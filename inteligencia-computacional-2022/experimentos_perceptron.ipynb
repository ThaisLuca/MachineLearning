{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c786d6",
   "metadata": {},
   "source": [
    "Aluna: Thais Luca Marques de Almeida\n",
    "\n",
    "DRE: 122024801"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6dd743",
   "metadata": {},
   "source": [
    "# Código para as Questões 7, 8, 9 e 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39e161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e095ff",
   "metadata": {},
   "source": [
    "Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c313f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_plot(x,func):\n",
    "    '''\n",
    "        Obtém os coeficientes angular e linear da reta da função\n",
    "        no formato y(x) = mx + b\n",
    "\n",
    "        Args:\n",
    "            x: pontos no eixo x\n",
    "            func: vetor de pesos [w0,w1,w2] correspondente\n",
    "        Result:\n",
    "            valores correspondentes aos parâmetros func \n",
    "            e x passados como parâmetro\n",
    "    '''\n",
    "\n",
    "    # Teste para evitar divisão por zero\n",
    "    if np.all(func==0):\n",
    "        return np.zeros(len(x))\n",
    "\n",
    "    m = -func[0]/func[1] # coeficiente angular\n",
    "    b = -func[2]/func[1] # coeficiente linear\n",
    "    \n",
    "    # Gera a linha dados os pontos do eixo x\n",
    "    return x * m + b\n",
    "\n",
    "def plot(X,y_true,h_func):\n",
    "    '''\n",
    "        Função que \"plota\" os dados de treinamento junto à hipótese\n",
    "\n",
    "        Args:\n",
    "            X: valores dos dados de treinamento [-1,1] x [-1,1]\n",
    "            Y: labels dos dados de treinamento \n",
    "            h_func: função hipótese do perceptron\n",
    "\n",
    "    '''\n",
    "\n",
    "    plt.figure()\n",
    "    \n",
    "    # Filtra e plota os exemplos negativos\n",
    "    x_negs = [X[i][0] for i in range(len(X)) if y_true[i] < 0] \n",
    "    y_negs = [X[i][1] for i in range(len(X)) if y_true[i] < 0]\n",
    "    plt.scatter(x_negs,y_negs,color='red')\n",
    "    \n",
    "    # Filtra e plota os exemplos positivos\n",
    "    x_pos = [X[i][0] for i in range(len(X)) if y_true[i] > 0]\n",
    "    y_pos = [X[i][1] for i in range(len(X)) if y_true[i] > 0]\n",
    "    plt.scatter(x_pos,y_pos,color='green')\n",
    "    \n",
    "    # Plota a hipótese\n",
    "    xplt = np.linspace(-1, 1, 100)\n",
    "    yplt2 = get_line_plot(xplt, h_func)\n",
    "    plt.plot(xplt,yplt2,color='black',label='$g(x)$')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def create_target_function():\n",
    "    '''\n",
    "        Gera a função target que determina a classificação dos dados de treinamento\n",
    "\n",
    "        Result:\n",
    "            array com três posições w0 = 0, w1 = m, w2 = b, \n",
    "            onde m e b são os coeficientes angular e linear, \n",
    "            respectivamente\n",
    "    '''\n",
    "\n",
    "    #Pego dois pontos aleatórios no espaço [-1,1] x [-1,1]\n",
    "    p0 = random.uniform(-1,1), random.uniform(-1,1)\n",
    "    p1 = random.uniform(-1,1), random.uniform(-1,1)\n",
    "\n",
    "    #Calcula o coeficiente angular \n",
    "    m = (p1[1]-p0[1])/(p1[0]-p0[0])\n",
    "    \n",
    "    # Calcula o coeficiente linear\n",
    "    b = p0[1] - (p0[0] * m)\n",
    "    \n",
    "    # Gero a função target \n",
    "    # w0 = m, w1 = -1, w2= b\n",
    "    # y = m*x + b -> m*x -y + b = 0\n",
    "    return np.array([m,-1,b])\n",
    "\n",
    "def generate_training_data(N,f_target):\n",
    "    '''\n",
    "        Gera um conjunto de dados linearmente separável pela função target \n",
    "        (desconhecida pelo perceptron)\n",
    "\n",
    "        Args:\n",
    "            N: número de exemplos a serem gerados\n",
    "            f_target: função target que separa esses dados\n",
    "        Result:\n",
    "            X_sample: vetor contendo os pontos (x,y) dos dados de treinamento e;\n",
    "            y_sample: vetor contendo as labels dos dados de treinamento\n",
    "    '''\n",
    "    y_sample = []\n",
    "\n",
    "    # Gerando a amostra de N pontos no espaço [-1,1] x [-1,1]\n",
    "    X_sample = np.random.uniform(low=-1, high=1, size=(N,2))\n",
    "    X_sample = [np.concatenate((X_sample[i],np.array([1.]))) for i in range(N)]\n",
    "    for i in range(N):\n",
    "        y_sample.append(1 if np.dot(f_target,X_sample[i]) > 0 else -1) # Classificação do ponto gerado segundo a função target passada como parâmetro\n",
    "    \n",
    "    return X_sample, np.array(y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5ab74",
   "metadata": {},
   "source": [
    "***Classe Perceptron***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557b3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    '''\n",
    "        Classe que implementa o Perceptron e o PLA\n",
    "    '''\n",
    "\n",
    "    def __init__(self,show_plot=False):\n",
    "        self.g = np.zeros(3)\n",
    "        self.show_plot = show_plot\n",
    "\n",
    "    def __sign(self,func,pt):\n",
    "        '''\n",
    "            Define a classificação do ponto de acordo com o produto interno \n",
    "            entre o ponto e a função\n",
    "            \n",
    "            Args:\n",
    "                func: função que separa os dados em +1 ou -1\n",
    "                pt: ponto a ser classificado\n",
    "            Result:\n",
    "                valor inteiro correspondente ao rótulo do dado segundo func\n",
    "        '''\n",
    "        return 1 if np.dot(func,pt) > 0 else -1\n",
    "\n",
    "    def __update_weights(self,X,y):\n",
    "        '''\n",
    "            Atualiza o vetor de pesos da função hipótese g\n",
    "            O vetor de pesos é atualizado de acordo com um dos pontos \n",
    "            classificados incorretamente\n",
    "            O ponto é escolhido de forma aleatória dentro do conjunto\n",
    "\n",
    "            Args:\n",
    "                X: dados de treinamento classificados de forma incorreta\n",
    "                y: classificação dada por g (incorreta)\n",
    "            Result:\n",
    "                os pesos da reta g atualizados de acordo com um dos pontos\n",
    "                classificados de forma incorreta escolhido de forma aleatória\n",
    "        '''\n",
    "\n",
    "        #Escolhe um ponto aleatoriamente\n",
    "        i = random.randint(0,len(X)-1)\n",
    "\n",
    "        # weight vector\n",
    "        w = self.g\n",
    "        \n",
    "        #Atualiza os pesos\n",
    "        # w(t+1) = w(t) + y(t)*x(t)\n",
    "        # Nesse caso, vamos usar w(t+1) = w(t) - y(t)*x(t) \n",
    "        # porque consideramos m*x - y + b = 0\n",
    "        w = w - y[i]*X[i]\n",
    "        \n",
    "        return w\n",
    "\n",
    "    def __get_miss_classified_examples(self,X,y_pred,y_true):\n",
    "        '''\n",
    "            Compara os rótulos de cada exemplo y_pred com y_true para retornar \n",
    "            quais pontos não foram classificados corretamente por g\n",
    "\n",
    "            Args:\n",
    "                X: pontos (x,y) do conjunto de treinamento\n",
    "                y_pred: rótulos previstos por g (hipótese)\n",
    "                y_true: valores reais do rótulos de acordo com a função target \n",
    "                desconhecida\n",
    "            Returns:\n",
    "                as coordenadas dos pontos classificados incorretamente \n",
    "                e os rótulos divergentes dos rótulos reais\n",
    "        '''\n",
    "        X_mislabeled,y_mislabeled = [],[]\n",
    "        for i in range(len(y_true)):\n",
    "            if y_pred[i] != y_true[i]:\n",
    "                X_mislabeled.append(X[i])\n",
    "                y_mislabeled.append(y_pred[i])\n",
    "        return X_mislabeled,y_mislabeled\n",
    "\n",
    "    def predict(self, X, function):\n",
    "        '''\n",
    "            Realiza a predição de todos os pontos do conjunto de treinamento \n",
    "            de acordo com a função passada como parâmetro\n",
    "\n",
    "            Args:\n",
    "                X: pontos (x,y) do conjunto de treinamento\n",
    "                function: função que irá classificar os pontos\n",
    "            Return:\n",
    "                lista de rótulos de classificação de acordo com a \n",
    "                função function\n",
    "        '''\n",
    "        return [self.__sign(function,x) for x in X]\n",
    "\n",
    "    def train(self,X,y):\n",
    "        '''\n",
    "            Perceptron Learning Algorithm\n",
    "\n",
    "            Começando com g contendo apenas valores nulos, \n",
    "            a reta é atualizada de acordo com os exemplos que \n",
    "            não foram classificados corretamente.\n",
    "            O algoritmo termina quando não há mais pontos classificados \n",
    "            incorretamente.\n",
    "            \n",
    "            Args:\n",
    "                X: pontos (x,y) do conjunto de treinamento\n",
    "                y: rótulos dos pontos passados como parâmetro\n",
    "            Return:\n",
    "                número de iterações necessárias para conversão do modelo\n",
    "        '''\n",
    "\n",
    "        # Inicializo o número de iterações como zero\n",
    "        n_iteractions = 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # Inicializo os arrays de predição \n",
    "            # e exemplos que não foram classificados corretamente\n",
    "            X_miss_classified, y_miss_classified, predicted = [], [], []\n",
    "\n",
    "            # Predição dos exemplos pela função hipótese\n",
    "            predicted = self.predict(X,self.g)\n",
    "        \n",
    "            # Coleto todos os pontos que não foram classificados corretamente\n",
    "            X_miss_classified,y_miss_classified = self.__get_miss_classified_examples(X,predicted,y)\n",
    "        \n",
    "            #print(f'Número de pontos classificados de forma errada: {len(X_miss_classified)}')\n",
    "\n",
    "            # Desenho os pontos e as funções na tela (opcional)\n",
    "            if self.show_plot:\n",
    "                plot(X,y,self.g)\n",
    "\n",
    "            # Se todos os pontos foram classificados corretamente, \n",
    "            # encerra o programa\n",
    "            if len(X_miss_classified) == 0:\n",
    "                break\n",
    "\n",
    "            # Uso os pontos que não foram classificados corretamente \n",
    "            # para ajustar os pesos de g\n",
    "            self.g = self.__update_weights(X_miss_classified,y_miss_classified)\n",
    "            \n",
    "            # Cada vez que atualizo os pesos, conto uma iteração\n",
    "            n_iteractions += 1\n",
    "            \n",
    "        return n_iteractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aff36e",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd24118",
   "metadata": {},
   "source": [
    "***Questão 7***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e7e8d",
   "metadata": {},
   "source": [
    "Média de iterações necessárias para conversão do PLA usando 10 pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93e9c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.437\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de pontos e interações\n",
    "N = 10\n",
    "total_iteractions = 0\n",
    "\n",
    "# True para mostrar o gráfico a cada iteração; False cc\n",
    "show_plot = False\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # Inicializa a função objetivo\n",
    "    f_target = create_target_function()\n",
    "\n",
    "    # Gera o conjunto de treinamento\n",
    "    X,y = generate_training_data(N,f_target)\n",
    "\n",
    "    # Inicializa a classe perceptron\n",
    "    model = Perceptron(show_plot=show_plot)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    n_iteractions = model.train(X,y)\n",
    "\n",
    "    # Armazena o número de iterações da rodada atual\n",
    "    total_iteractions += n_iteractions\n",
    "\n",
    "print(total_iteractions/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba52a10",
   "metadata": {},
   "source": [
    "Resposta letra B. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ab7fb",
   "metadata": {},
   "source": [
    "***Questão 8***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184ddca",
   "metadata": {},
   "source": [
    "Média de probabilidade de f(x) != g(x) para 10 pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e61f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10979999999999804\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de pontos e número de vezes que f foi diferente de g\n",
    "N = 10\n",
    "n_divergencies = 0\n",
    "\n",
    "# True para mostrar o gráfico a cada iteração; False cc\n",
    "show_plot = False\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # Inicializa a função objetivo \n",
    "    f_target = create_target_function()\n",
    "\n",
    "    # Gera o conjunto de treinamento para treinar o Perceptron\n",
    "    X,y = generate_training_data(N,f_target)\n",
    "\n",
    "    # Inicializa a classe perceptron\n",
    "    model = Perceptron(show_plot=show_plot)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    n_iteractions = model.train(X,y)\n",
    "    \n",
    "    # Gero novos pontos para testar a divergência entre a função target e a hipótese aprendida\n",
    "    new_X, new_y = generate_training_data(N,f_target)\n",
    "    \n",
    "    # Uso o modelo pra fazer a predição dos novos dados\n",
    "    preds = []\n",
    "    preds = model.predict(new_X,model.g)\n",
    "    for y_true,y_pred in zip(new_y,preds):\n",
    "        if y_true != y_pred:\n",
    "            n_divergencies += 1/N\n",
    "\n",
    "print(n_divergencies/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe0ea4",
   "metadata": {},
   "source": [
    "Resposta letra C. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543d9d0",
   "metadata": {},
   "source": [
    "***Questão 9***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65accefa",
   "metadata": {},
   "source": [
    "Média de iterações necessárias para conversão do PLA usando 100 pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8719d871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.998\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de pontos e interações\n",
    "N = 100\n",
    "total_iteractions = 0\n",
    "\n",
    "# True para mostrar o gráfico a cada iteração; False cc\n",
    "show_plot = False\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # Inicializa a função objetivo\n",
    "    f_target = create_target_function()\n",
    "\n",
    "    # Gera o conjunto de treinamento\n",
    "    X,y = generate_training_data(N,f_target)\n",
    "\n",
    "    # Inicializa a classe perceptron\n",
    "    model = Perceptron(show_plot=show_plot)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    n_iteractions = model.train(X,y)\n",
    "    \n",
    "    # Armazena o número de iterações da rodada\n",
    "    total_iteractions += n_iteractions\n",
    "\n",
    "print(total_iteractions/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950bd1d",
   "metadata": {},
   "source": [
    "Resposta letra B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d96209",
   "metadata": {},
   "source": [
    "***Questão 10***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaae583",
   "metadata": {},
   "source": [
    "Média de probabilidade de f(x) != g(x) para 100 pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5376e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012619999999999775\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de pontos e número de vezes que f foi diferente de g\n",
    "N = 100\n",
    "n_divergencies = 0\n",
    "\n",
    "# True para mostrar o gráfico a cada iteração; False cc\n",
    "show_plot = False\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # Inicializa a função objetivo\n",
    "    f_target = create_target_function()\n",
    "\n",
    "    # Gera o conjunto de treinamento\n",
    "    X,y = generate_training_data(N,f_target)\n",
    "\n",
    "    # Inicializa a classe perceptron\n",
    "    model = Perceptron(show_plot=show_plot)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    n_iteractions = model.train(X,y)\n",
    "    \n",
    "    # Gero novos pontos para testar a divergência entre a função target e a hipótese aprendida\n",
    "    new_X, new_y = generate_training_data(N,f_target)\n",
    "    \n",
    "    # Uso o modelo pra fazer a predição dos novos dados\n",
    "    preds = []\n",
    "    preds = model.predict(new_X,model.g)\n",
    "    for y_true,y_pred in zip(new_y,preds):\n",
    "        if y_true != y_pred:\n",
    "            n_divergencies += 1/N\n",
    "\n",
    "print(n_divergencies/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307753ee",
   "metadata": {},
   "source": [
    "Resposta letra B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94af99",
   "metadata": {},
   "source": [
    "## Interpretação dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5882958e",
   "metadata": {},
   "source": [
    "Como os dados são linearmente separáveis, o algoritmo consegue convergir a partir da quantidade de pontos usados no treinamento. Analisando o número de iterações necessárias para convergência, a média se dá pelo número de pontos presentes no conjunto de treinamento. Ou seja, a quantidade de vezes que a reta precisa se ajustar. Quando aumentamos consideravelmente o número de pontos do conjunto, esse valor também aumenta, uma vez que o algoritmo tem mais pontos para ajustar os pesos da função hipótese. Já quando observamos a probabilidade de g divergir de f, também podemos observar que quando aumentamos o número de pontos do conjunto, podemos encontrar retas melhores. Temos uma maior precisão na classificação dos pontos, o que diminui a probabilidade de g divergir de f. Quando utilizados poucos pontos (N=10), temos uma maior probabilidade de g divergir de f porque podemos encontrar retas que não descrevem tão bem a função. Quanto maior o número de pontos, mais informação temos para descrever a função. Consequentemente, maior o número de iterações."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
